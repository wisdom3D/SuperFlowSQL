
  # =======================================================================================================================#
  # SuperFlowSQL  
  # =======================================================================================================================#

services:
  # ==========================
  # POSTGRESQL
  # ==========================
  postgres:
    image: postgres:15
    container_name: postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB_AIRFLOW}
    ports:
      - "${POSTGRES_PORT}:${POSTGRES_PORT}"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - data_platform

  
  # ==========================
  #  PGADMIN (Configuration par fichier généré)
  # ==========================
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_PASSWORD}
      # Indique à PgAdmin d'utiliser le fichier monté
      PGADMIN_SETUP_SERVER_JSON_FILE: /pgadmin4/servers.json
    ports:
      - "${PGADMIN_PORT}:80"
    volumes:
      # L'utilisateur doit d'abord exécuter le script Python pour créer ce fichier
      - ./pgadmin_servers.json:/pgadmin4/servers.json
    depends_on:
      - postgres
    networks:
      - data_platform
    # Le champ 'command' est complètement retiré pour utiliser l'entrée par défaut
    

  # ==========================
  #  AIRFLOW - WEBSERVER
  # ==========================
  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    image: custom-airflow:latest
    container_name: airflow-webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW_DB_CONN}
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__WEBSERVER__DEFAULT_UI_TIMEZONE: UTC
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
    volumes:
      - ./dags:/opt/airflow/dags
      - airflow_logs:/opt/airflow/logs
      - airflow_plugins:/opt/airflow/plugins
    ports:
      - "${AIRFLOW_PORT}:8080"
    depends_on:
      - postgres
    networks:
      - data_platform
    entrypoint: /bin/bash
    command: -c "
      airflow db init &&
      airflow users create --username ${AIRFLOW_USER} --password ${AIRFLOW_PASSWORD} --firstname Airflow --lastname Admin --role Admin --email ${AIRFLOW_EMAIL} &&
      airflow connections delete 'postgres_default' || true &&
      airflow connections add 'postgres_default' \
        --conn-type 'postgres' \
        --conn-login '${POSTGRES_USER}' \
        --conn-password '${POSTGRES_PASSWORD}' \
        --conn-host '${POSTGRES_HOST}' \
        --conn-port '${POSTGRES_PORT}' \
        --conn-schema '${POSTGRES_DB_AIRFLOW}' &&
      exec airflow webserver
      "


  # ==========================
  #  AIRFLOW - SCHEDULER
  # ==========================
  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    image: custom-airflow:latest
    container_name: airflow-scheduler
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: ${AIRFLOW_DB_CONN}
      AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
      AIRFLOW__WEBSERVER__DEFAULT_UI_TIMEZONE: UTC
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
    volumes:
      - ./dags:/opt/airflow/dags
      - airflow_logs:/opt/airflow/logs
      - airflow_plugins:/opt/airflow/plugins
    depends_on:
      - postgres
      - airflow-webserver
    networks:
      - data_platform
    entrypoint: /bin/bash
    command: -c "airflow scheduler"


  # ==========================
  #  SUPERSET
  # ==========================
  superset:
    image: apache/superset:3.0.2
    container_name: superset
    restart: always
    depends_on:
      - postgres
    environment:
      SUPERSET_SECRET_KEY: ${SUPERSET_SECRET_KEY}
      SUPERSET_DATABASE_URI: ${SUPERSET_DB_CONN}
    ports:
      - "${SUPERSET_PORT}:8088"
    volumes:
      - superset_home:/app/superset_home
      - superset_logs:/app/superset_logs
    networks:
      - data_platform
    command: >
      /bin/bash -c "superset db upgrade &&
                    superset fab create-admin --username ${SUPERSET_USER} --password ${SUPERSET_PASSWORD} --firstname Admin --lastname User --email ${SUPERSET_EMAIL} &&
                    superset init &&
                    superset run -h 0.0.0.0 -p 8088"

# ==========================
#  NETWORKS & VOLUMES
# ==========================
networks:
  data_platform:

volumes:
  postgres_data:
  airflow_logs:
  airflow_plugins:
  superset_home:
  superset_logs: